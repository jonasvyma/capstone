import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

st.set_page_config(page_title="Star Wars MoC Loose Sales — EDA", layout="wide")

st.title("Star Wars MoC Loose Sales — EDA")
st.write("Upload a CSV or use the bundled sample to explore insights interactively.")

# Sidebar: file input
st.sidebar.header("Data Input")
use_sample = st.sidebar.checkbox("Use bundled sample dataset", value=True)
uploaded = st.sidebar.file_uploader("Upload your CSV", type=["csv"])

if use_sample:
    df = pd.read_csv("/mnt/data/starwars_mocloose_sales_202510061222.csv", low_memory=False)
else:
    if uploaded is None:
        st.warning("Upload a CSV or enable 'Use bundled sample dataset' in the sidebar.")
        st.stop()
    df = pd.read_csv(uploaded, low_memory=False)

# Attempt to parse likely date columns
for col in df.columns:
    if any(k in col.lower() for k in ["date", "time", "timestamp"]):
        try:
            df[col] = pd.to_datetime(df[col], errors="coerce", infer_datetime_format=True)
        except Exception:
            pass

st.subheader("Shape & Memory")
st.write(f"Rows: {df.shape[0]:,}  •  Columns: {df.shape[1]}")
st.write(df.memory_usage(deep=True).sum())

# Column profiling
with st.expander("Schema & Missingness", expanded=True):
    dtypes = df.dtypes.astype(str).rename("dtype")
    missing = df.isna().sum().rename("missing_count")
    profile = pd.concat([dtypes, missing], axis=1)
    profile["missing_pct"] = (profile["missing_count"] / len(df) * 100).round(2)
    st.dataframe(profile.reset_index(names="column"))

# Optional filtering
with st.expander("Filtering"):
    filters = {}
    cat_cols = [c for c in df.columns if df[c].dtype == "object" or df[c].dtype.name == "category"]
    num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    date_cols = [c for c in df.columns if pd.api.types.is_datetime64_any_dtype(df[c])]

    if cat_cols:
        col = st.selectbox("Categorical column", ["(none)"] + cat_cols, index=0)
        if col != "(none)":
            options = st.multiselect("Include values", sorted([x for x in df[col].dropna().unique().tolist() if isinstance(x, (str, int, float))]))
            if options:
                filters[col] = df[col].isin(options)

    if num_cols:
        coln = st.selectbox("Numeric column", ["(none)"] + num_cols, index=0, key="numfilter")
        if coln != "(none)":
            vmin, vmax = float(df[coln].min()), float(df[coln].max())
            sel = st.slider("Range", min_value=vmin, max_value=vmax, value=(vmin, vmax))
            filters[coln] = df[coln].between(sel[0], sel[1])

    if date_cols:
        cold = st.selectbox("Datetime column", ["(none)"] + date_cols, index=0, key="datefilter")
        if cold != "(none)":
            dmin, dmax = df[cold].min(), df[cold].max()
            if pd.notna(dmin) and pd.notna(dmax):
                sel = st.date_input("Date range", value=(dmin.date(), dmax.date()), min_value=dmin.date(), max_value=dmax.date())
                filters[cold] = df[cold].between(pd.to_datetime(sel[0]), pd.to_datetime(sel[1]))

    if filters:
        import numpy as _np
        mask = _np.logical_and.reduce([cond for cond in filters.values()])
        df = df[mask]

st.subheader("Data Preview")
st.dataframe(df.head(20))

# Distributions for numeric columns
st.subheader("Distributions")
num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
if not num_cols:
    st.info("No numeric columns detected.")
else:
    col = st.selectbox("Choose a numeric column", num_cols)
    fig, ax = plt.subplots()
    ax.hist(df[col].dropna(), bins=30)
    ax.set_title(f"Histogram of {col}")
    ax.set_xlabel(col)
    ax.set_ylabel("Count")
    st.pyplot(fig)

# Top categories
st.subheader("Top Categories")
cat_cols = [c for c in df.columns if df[c].dtype == "object" or df[c].dtype.name == "category"]
if not cat_cols:
    st.info("No categorical columns detected.")
else:
    col = st.selectbox("Choose a categorical column", cat_cols, key="catdist")
    vc = df[col].value_counts(dropna=False).head(20)
    fig2, ax2 = plt.subplots()
    vc.plot(kind="bar", ax=ax2)
    ax2.set_title(f"Top categories for {col}")
    ax2.set_xlabel(col)
    ax2.set_ylabel("Count")
    st.pyplot(fig2)

# Correlation heatmap (numeric)
st.subheader("Correlation (Pearson)")
if len(num_cols) < 2:
    st.info("Need at least two numeric columns for correlation.")
else:
    corr = df[num_cols].corr(numeric_only=True)
    fig3, ax3 = plt.subplots()
    cax = ax3.imshow(corr.values, aspect="auto")
    ax3.set_xticks(range(len(corr.columns)))
    ax3.set_xticklabels(corr.columns, rotation=45, ha="right")
    ax3.set_yticks(range(len(corr.index)))
    ax3.set_yticklabels(corr.index)
    ax3.set_title("Correlation matrix")
    fig3.colorbar(cax)
    st.pyplot(fig3)

# Time series (if a datetime column exists)
st.subheader("Time Series")
date_cols = [c for c in df.columns if pd.api.types.is_datetime64_any_dtype(df[c])]
if not date_cols or not num_cols:
    st.info("Need at least one datetime and one numeric column.")
else:
    dc = st.selectbox("Datetime column", date_cols)
    nc = st.selectbox("Numeric column", num_cols, key="tsnum")
    agg = st.selectbox("Aggregation", ["sum", "mean", "median", "count"], index=0)
    freq = st.selectbox("Resample frequency", ["D", "W", "M", "Q", "Y"], index=2, help="D=Day, W=Week, M=Month, Q=Quarter, Y=Year")
    ts = df[[dc, nc]].dropna()
    ts = ts.set_index(dc).sort_index()
    if agg == "sum":
        r = ts[nc].resample(freq).sum()
    elif agg == "mean":
        r = ts[nc].resample(freq).mean()
    elif agg == "median":
        r = ts[nc].resample(freq).median()
    else:
        r = ts[nc].resample(freq).count()

    fig4, ax4 = plt.subplots()
    ax4.plot(r.index, r.values)
    ax4.set_title(f"{agg.title()} of {nc} by {freq}")
    ax4.set_xlabel("Date")
    ax4.set_ylabel(nc)
    st.pyplot(fig4)

st.caption("Tip: Use the filtering expander to narrow data before plotting. Correlation matrix uses Pearson correlation over numeric columns.")
